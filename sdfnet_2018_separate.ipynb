{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from model_def import create_sdnet_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_TYPE = 'D'\n",
    "ROOT_DIR = f'/home/khanhhh/data_1/courses/practical_project_1/codes/dataset/SDNET2018/'\n",
    "DIR_IN = f'{ROOT_DIR}{IMG_TYPE}/'\n",
    "DIR_TMP = f'{DIR_IN}/tmp/'\n",
    "os.makedirs(DIR_TMP, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/khanhhh/data_1/courses/practical_project_1/codes/dataset/SDNET2018/D/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR_IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crack_paths = []\n",
    "noncrack_paths = []\n",
    "for i, path in enumerate(Path(DIR_IN).glob('**/*.jpg')):\n",
    "    if not path.is_file():\n",
    "        continue\n",
    "    folder_type = path.parent.name[0]\n",
    "    if folder_type != 'C' and folder_type != 'U':\n",
    "        continue\n",
    "        \n",
    "    if path.parent.name[0] == 'C':\n",
    "        crack_paths.append(path)\n",
    "    else: \n",
    "        noncrack_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all images = 27242\n",
      "number of crack images = 4050\n",
      "number of non crack images = 23192\n",
      "ratio crack/noncrack = 0.1746291824767161\n"
     ]
    }
   ],
   "source": [
    "n_crack = len(crack_paths)\n",
    "n_noncrack = len(noncrack_paths)\n",
    "n_total = n_crack + n_noncrack\n",
    "print(f'number of all images = {n_total}')\n",
    "print(f'number of crack images = {n_crack}')\n",
    "print(f'number of non crack images = {n_noncrack}')\n",
    "print(f'ratio crack/noncrack = {float(n_crack)/n_noncrack}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split dataset into train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_x = crack_paths + noncrack_paths\n",
    "y = [1]*n_crack + [0]*n_noncrack\n",
    "paths_train_x, paths_test_x,  train_y, test_y = train_test_split(paths_x, y,test_size=0.2)\n",
    "paths_train_x, paths_valid_x, train_y, valid_y = train_test_split(paths_train_x, train_y, test_size=0.2)\n",
    "\n",
    "for path in paths_train_x:\n",
    "    rel_path = str(path.parents[0].name)+'/'+path.name\n",
    "    path_dst = Path(f'{DIR_TMP}/train/{rel_path}')\n",
    "    os.makedirs(path_dst.parents[0], exist_ok=True)\n",
    "    shutil.copy(path, path_dst)\n",
    "\n",
    "for path in paths_valid_x:\n",
    "    rel_path = str(path.parents[0].name)+'/'+path.name\n",
    "    path_dst = Path(f'{DIR_TMP}/valid/{rel_path}')\n",
    "    os.makedirs(path_dst.parents[0], exist_ok=True)\n",
    "    shutil.copy(path, path_dst) \n",
    "\n",
    "for path in paths_test_x:\n",
    "    rel_path = str(path.parents[0].name)+'/'+path.name\n",
    "    path_dst = Path(f'{DIR_TMP}/test/{rel_path}')\n",
    "    os.makedirs(path_dst.parents[0], exist_ok=True)\n",
    "    shutil.copy(path, path_dst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 8716, percent = 0.6399412628487519\n",
      "valid size = 2180, percent = 0.16005873715124816\n",
      "test size  = 2724, percent  = 0.2\n"
     ]
    }
   ],
   "source": [
    "print(f'train size = {len(train_y)}, percent = {float(len(train_y))/n_total}')\n",
    "print(f'valid size = {len(valid_y)}, percent = {float(len(valid_y))/n_total}')\n",
    "print(f'test size  = {len(test_y)}, percent  = {float(len(test_y)) /n_total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8716 images belonging to 2 classes.\n",
      "Found 2181 images belonging to 2 classes.\n",
      "Found 2725 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "train_flow  = train_gen.flow_from_directory(\n",
    "        f'{DIR_TMP}/train/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=100,\n",
    "        class_mode='categorical')\n",
    "\n",
    "valid_gen = ImageDataGenerator(rescale=1./255)\n",
    "valid_flow  = train_gen.flow_from_directory(\n",
    "        f'{DIR_TMP}/valid/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=100,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_flow  = train_gen.flow_from_directory(\n",
    "        f'{DIR_TMP}/test/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=100,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "\tn = 8716, n_crack = 1284, n_noncrack = 7432. ratio = 0.1727664155005382\n",
      "valid:\n",
      "\tn = 2181, n_crack = 319, n_noncrack = 1862. ratio = 0.17132116004296455\n",
      "test:\n",
      "\tn = 2725, n_crack = 422, n_noncrack = 2303. ratio = 0.18323925314806774\n"
     ]
    }
   ],
   "source": [
    "print('train:')\n",
    "print(f'\\tn = {len(train_flow.classes)}, n_crack = {np.sum(train_flow.classes == 0)}, n_noncrack = {np.sum(train_flow.classes == 1)}. ratio = {np.sum(train_flow.classes == 0)/np.sum(train_flow.classes == 1)}')\n",
    "\n",
    "print('valid:')\n",
    "print(f'\\tn = {len(valid_flow.classes)}, n_crack = {np.sum(valid_flow.classes == 0)}, n_noncrack = {np.sum(valid_flow.classes == 1)}. ratio = {np.sum(valid_flow.classes == 0)/np.sum(valid_flow.classes == 1)}')\n",
    "\n",
    "print('test:')\n",
    "print(f'\\tn = {len(test_flow.classes)}, n_crack = {np.sum(test_flow.classes == 0)}, n_noncrack = {np.sum(test_flow.classes == 1)}. ratio = {np.sum(test_flow.classes == 0)/np.sum(test_flow.classes == 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 8194      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 23,986,946\n",
      "Trainable params: 23,967,810\n",
      "Non-trainable params: 19,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model_def import create_sdnet_model\n",
    "model = create_sdnet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'{ROOT_DIR}/models/weight_img_{IMG_TYPE}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 1.1619 - acc: 0.7396 - val_loss: 0.5453 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54532, saving model to /home/khanhhh/data_1/courses/practical_project_1/codes/dataset/SDNET2018//models/weight_img_D.hdf5\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 0.4577 - acc: 0.8396 - val_loss: 0.4750 - val_acc: 0.8537\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54532 to 0.47502, saving model to /home/khanhhh/data_1/courses/practical_project_1/codes/dataset/SDNET2018//models/weight_img_D.hdf5\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 0.4607 - acc: 0.8405 - val_loss: 1.0675 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.47502\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 0.4350 - acc: 0.8467 - val_loss: 0.5028 - val_acc: 0.8469\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.47502\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 0.4260 - acc: 0.8525 - val_loss: 0.5929 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47502\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 0.4302 - acc: 0.8480 - val_loss: 2.3135 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47502\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 0.4419 - acc: 0.8474 - val_loss: 0.4657 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47502 to 0.46570, saving model to /home/khanhhh/data_1/courses/practical_project_1/codes/dataset/SDNET2018//models/weight_img_D.hdf5\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 0.4238 - acc: 0.8471 - val_loss: 0.5279 - val_acc: 0.8308\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.46570\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 0.4182 - acc: 0.8503 - val_loss: 0.4379 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.46570 to 0.43787, saving model to /home/khanhhh/data_1/courses/practical_project_1/codes/dataset/SDNET2018//models/weight_img_D.hdf5\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 0.4051 - acc: 0.8565 - val_loss: 0.9014 - val_acc: 0.7084\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.43787\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "check_point = ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_flow,\n",
    "        steps_per_epoch=len(train_flow),\n",
    "        epochs=n_epochs,\n",
    "        validation_data=valid_flow,\n",
    "        validation_steps=len(valid_flow), callbacks=[check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe89edf9a58>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(n_epochs)\n",
    "plt.plot(x, history.history['loss'], '-b', label = 'train_loss')\n",
    "plt.plot(x, history.history['val_loss'], '-r', label='validation_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy on the same image type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report\n",
    "def calc_accuracy(model, generator):\n",
    "    preds = model.predict_generator(generator, steps=len(generator))\n",
    "    preds_idx = np.argmax(preds, axis=1) # multiple categories\n",
    "    class_names = [key for key in generator.class_indices.keys()]\n",
    "    report = classification_report(generator.classes, preds_idx, target_names = class_names)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.00      0.00      0.00       422\n",
      "          UD       0.85      1.00      0.92      2303\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2725\n",
      "   macro avg       0.42      0.50      0.46      2725\n",
      "weighted avg       0.71      0.84      0.77      2725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.load_weights(model_path)\n",
    "report = calc_accuracy(model, test_flow)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_test_images = 2725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CD': 0, 'UD': 1}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'n_test_images = {len(test_flow.classes)}')\n",
    "test_flow.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_crack_pred = 0, n_noncrack_pred = 2725\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_generator(test_flow, steps=len(test_flow))\n",
    "preds_idx = np.argmax(preds, axis=1) # multiple categories\n",
    "n_crack_pred = np.sum(preds_idx == 0)\n",
    "n_noncrack_pred = np.sum(preds_idx == 1)\n",
    "print(f'n_crack_pred = {n_crack_pred}, n_noncrack_pred = {n_noncrack_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy on other image type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image type P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24334 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_TYPE_1 = 'P'\n",
    "DIR_IN_1 = f'{ROOT_DIR}{IMG_TYPE_1}'\n",
    "test_gen_1 = ImageDataGenerator(rescale=1.0/255)\n",
    "test_flow_1 = test_gen_1.flow_from_directory(\n",
    "        DIR_IN_1,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=100,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CP': 0, 'UP': 1}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flow_1.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = calc_accuracy(model, test_flow_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_crack_pred = 13, n_noncrack_pred = 24321\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_generator(test_flow_1, steps=len(test_flow_1))\n",
    "preds_idx = np.argmax(preds, axis=1) # multiple categories\n",
    "n_crack_pred = np.sum(preds_idx == 0)\n",
    "n_noncrack_pred = np.sum(preds_idx == 1)\n",
    "print(f'n_crack_pred = {n_crack_pred}, n_noncrack_pred = {n_noncrack_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of model trained on images of type D on images of type P\n",
      "\t n_crack = 2608, n_noncrack = 21726\n",
      "\t crack/noncrack ratio = 0.12004050446469668\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CP       0.15      0.00      0.00      2608\n",
      "          UP       0.89      1.00      0.94     21726\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     24334\n",
      "   macro avg       0.52      0.50      0.47     24334\n",
      "weighted avg       0.81      0.89      0.84     24334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_noncrack = np.sum(test_flow_1.classes == 1)\n",
    "n_crack = np.sum(test_flow_1.classes == 0)\n",
    "print(f'result of model trained on images of type {IMG_TYPE} on images of type {IMG_TYPE_1}')\n",
    "print(f'\\t n_crack = {n_crack}, n_noncrack = {n_noncrack}')\n",
    "print(f'\\t crack/noncrack ratio = {float(n_crack)/n_noncrack}')\n",
    "print(f'\\n{report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image type W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18138 images belonging to 2 classes.\n",
      "/home/khanhhh/data_1/courses/practical_project_1/codes/dataset/SDNET2018/W\n"
     ]
    }
   ],
   "source": [
    "IMG_TYPE_2 = 'W'\n",
    "DIR_IN_2 = f'{ROOT_DIR}{IMG_TYPE_2}'\n",
    "test_gen_2 = ImageDataGenerator(rescale=1.0/255)\n",
    "test_flow_2 = test_gen_1.flow_from_directory(\n",
    "        DIR_IN_2,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=100,\n",
    "        class_mode='categorical')\n",
    "print(DIR_IN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CW': 0, 'UW': 1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flow_2.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = calc_accuracy(model, test_flow_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of model trained on images of type D on images of type W\n",
      "\t n_crack = 3851, n_noncrack = 14287\n",
      "\t crack/noncrack ratio = 0.2695457408833205\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          CW       0.20      0.00      0.00      3851\n",
      "          UW       0.79      1.00      0.88     14287\n",
      "\n",
      "   micro avg       0.79      0.79      0.79     18138\n",
      "   macro avg       0.49      0.50      0.44     18138\n",
      "weighted avg       0.66      0.79      0.69     18138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_noncrack = np.sum(test_flow_2.classes == 1)\n",
    "n_crack = np.sum(test_flow_2.classes == 0)\n",
    "print(f'result of model trained on images of type {IMG_TYPE} on images of type {IMG_TYPE_2}')\n",
    "print(f'\\t n_crack = {n_crack}, n_noncrack = {n_noncrack}')\n",
    "print(f'\\t crack/noncrack ratio = {float(n_crack)/n_noncrack}')\n",
    "print(f'\\n {report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
